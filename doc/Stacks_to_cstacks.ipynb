{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacks batch 7 - nb 1\n",
    "\n",
    "<br>\n",
    "\n",
    "**Batch 7** contains *all sequenced samples*, meaning samples from all lanes 1 through 5. This will be the first batch that includes samples from Lane 5. Lane 5 includes (1) 11 remaining samples unsequenced, (2) samples with slightly degraded DNA, and (3) reruns of samples that were possible contaminated during the library prep process. Samples that fit under the (2)nd definition have the name of that sample followed by `_c` to show that this is a sample created by combining two separate DNA extractions.  Samples that fit under the (3)rd definition have the name of that sample followed by `_2` to show that this is the second time the sample is being sequenced, but should be treated as a replacement for the first attempt, rather than a replicate. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "This notebook includes: \n",
    "1. `process_radtags` for Lane 5\n",
    "2. `ustacks` for Lane 5\n",
    "3. `cstacks - populations` for Lanes 1 through 5\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 8/14/2017\n",
    "\n",
    "### process_radtags, Lane 5\n",
    "\n",
    "\n",
    "The barcode file for the lane took a while to put together, since some of these samples are potential replacements for other samples. In order to avoid writing over existing files, I named the replacements with an additional \"`_2`\". Since I am a little worried about the samples that I prepared by combining two different extractions, I marked these with a \"`_c`\".\n",
    "\n",
    "The process_radtags code used here is the same that was used on Lanes 2 and 3 (other single read lanes) in [this notebook](https://github.com/mfisher5/PCod-Korea-repo/blob/master/notebooks/batch_4/Stacks%20batch%204%20-%201.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ran in terminal\n",
    "process_radtags -f /media/mfisher5/New\\ Volume/Mary/Raw\\ Data/1275_S13_L008_R1_001.fastq.gz \\\n",
    "-i gzfastq \\\n",
    "-y gzfastq \\\n",
    "-o samplesT142 \\\n",
    "-b scripts/barcodes_L5.txt \\\n",
    "-e sbfI \\\n",
    "-E phred33 \\\n",
    "-r -c -q -t 142 2>> samplesT142/process_radtags_outputL5.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Processing single-end data.\n",
    "Using Phred+33 encoding for quality scores.\n",
    "Reads will be truncated to 142bp\n",
    "Found 1 input file(s).\n",
    "Searching for single-end, inlined barcodes.\n",
    "Loaded 70 barcodes (6bp).\n",
    "Will attempt to recover barcodes with at most 1 mismatches.\n",
    "Processing file 1 of 1 [1275_S13_L008_R1_001.fastq.gz]\n",
    "  Processing RAD-Tags...1M...2M...3M...4M...5M...6M...7M...8M...9M...10M...11M...12M...13M...14M...15M...16M...17M...18M...19M...20M...21M...22M...23M...24M...25M...26M...27M...28M...29M...30M...31M...32M...33M...34M...35M...36M...37M...38M...39M...40M...41M...42M...43M...44M...45M...46M...47M...48M...49M...50M...51M...52M...53M...54M...55M...56M...57M...58M...59M...60M...61M...62M...63M...64M...65M...66M...67M...68M...69M...70M...71M...72M...73M...74M...75M...76M...77M...78M...79M...80M...81M...82M...83M...84M...85M...86M...87M...88M...89M...90M...91M...92M...93M...94M...95M...96M...97M...98M...99M...100M...101M...102M...103M...104M...105M...106M...107M...108M...109M...110M...111M...112M...113M...114M...115M...116M...117M...118M...119M...120M...121M...122M...123M...124M...125M...126M...127M...128M...129M...130M...131M...132M...133M...134M...135M...136M...137M...138M...139M...140M...141M...142M...143M...144M...145M...146M...147M...148M...149M...150M...151M...152M...153M...154M...155M...156M...157M...158M...159M...160M...161M...162M...163M...164M...165M...166M...167M...168M...169M...170M...171M...172M...173M...174M...175M...176M...177M...178M...179M...180M...181M...182M...183M...184M...185M...186M...187M...188M...189M...190M...191M...192M...193M...194M...195M...196M...197M...198M...199M...200M...201M...202M...203M...204M...205M...206M...207M...208M...209M...210M...211M...212M...213M...214M...215M...216M...217M...218M...219M...220M...221M...222M...223M...224M...225M...226M...227M...228M...229M...230M...231M...232M...233M...234M...235M...236M...237M...238M...239M...240M...241M...242M...243M...244M...245M...246M...247M...248M...249M...250M...251M...252M...253M...254M...255M...256M...257M...258M...259M...260M...261M...262M...263M...264M...265M...266M...267M...268M...269M...270M...271M...272M...273M...274M...275M...276M...277M...278M...279M...280M...281M...282M...283M...284M...285M...286M...287M...288M...289M...290M...291M...292M...293M...294M...295M...296M...297M...298M...299M...300M...301M...302M...303M...304M...305M...306M...307M...308M...309M...310M...311M...312M...313M...314M...315M...316M...317M...318M...319M...320M...321M...322M...323M...324M...325M...326M...327M...328M...329M...330M...331M...332M...333M...334M...335M...336M...337M...338M...339M...340M...341M...342M...343M...344M...345M...346M...347M...348M...349M...350M...351M...352M...353M...354M...355M...356M...357M...358M...359M...360M...361M...362M...363M...364M...365M...366M...367M...368M...369M...370M...371M...372M...373M...374M...375M...376M...377M...378M...379M...380M...381M...382M...383M...384M...385M...386M...387M...388M...389M...390M...391M...392M...393M...394M...395M...396M...397M...398M...399M...400M...401M...\n",
    "  401247240 total reads; -35483440 ambiguous barcodes; -60796955 ambiguous RAD-Tags; +35978738 recovered; -837191 low quality reads; 304129654 retained reads.`\n",
    "  \n",
    "`Closing files, flushing buffers...`\n",
    "\n",
    "`Outputing details to log: 'samplesT142/process_radtags.log'`\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "`401247240 total sequences`\n",
    "\n",
    " `35483440 ambiguous barcode drops (8.8%)`\n",
    " \n",
    "  ` 837191 low quality read drops (0.2%)`\n",
    "   \n",
    "` 60796955 ambiguous RAD-Tag drops (15.2%)`\n",
    " \n",
    "`304129654 retained reads (75.8%)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/samplesT142\n"
     ]
    }
   ],
   "source": [
    "cd samplesT142/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### ustacks, Lane 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir stacks_b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts\n"
     ]
    }
   ],
   "source": [
    "cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Produce Shell script to run ustacks to populations, for Lanes 1 and 2 combined data ######\r",
      "\r\n",
      "## MF 11/15/2016\r",
      "\r\n",
      "## Edited MF 1/17/2017\r",
      "\r\n",
      "## Edited MF 4/7/2017 FOR ALL POPULATIONS\r",
      "\r\n",
      "## Edited MF 8/14/2017 for Lane 5 Data\r",
      "\r\n",
      "\r",
      "\r\n",
      "###############\r",
      "\r\n",
      "## At the command line: python radtags_ustacks_genShellSR.py ARG1\r",
      "\r\n",
      "#ARG 1: input file, lane 5 barcodes. line format: <barcode> \\t <sampleID>\r",
      "\r\n",
      "\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head ustacks_counts_genshell8-14.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python ustacks_counts_genshell8-14.py barcodes_L5.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "cd /mnt/hgfs/Shared\\ Drive\\ D/Pacific\\ cod/DataAnalysis/PCod-Korea-repo/scripts\r\n",
      "\r\n",
      "#ustacks\r\n",
      "ustacks -t fastq -f samplesT142/JUK07_10.fq -r -d -o stacks_b7 -i 280 -m 5 -M 3 -p 6 --model_type bounded\r\n",
      "ustacks -t fastq -f samplesT142/JUK07_13.fq -r -d -o stacks_b7 -i 281 -m 5 -M 3 -p 6 --model_type bounded\r\n",
      "ustacks -t fastq -f samplesT142/JUK07_21.fq -r -d -o stacks_b7 -i 282 -m 5 -M 3 -p 6 --model_type bounded\r\n",
      "ustacks -t fastq -f samplesT142/JUK07_23.fq -r -d -o stacks_b7 -i 283 -m 5 -M 3 -p 6 --model_type bounded\r\n",
      "ustacks -t fastq -f samplesT142/JUK07_34.fq -r -d -o stacks_b7 -i 284 -m 5 -M 3 -p 6 --model_type bounded\r\n",
      "ustacks -t fastq -f samplesT142/JUK07_04.fq -r -d -o stacks_b7 -i 285 -m 5 -M 3 -p 6 --model_type bounded\r\n"
     ]
    }
   ],
   "source": [
    "!head ustacks_counts_lane5.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notice how I started at an ID of 280 -- this is because in batch 6, I had sample files up to an id of 264 in my ustacks script. however, when I copied over the files from batch 6 ustacks I have 828 files / 3 files per individual = 276 individuals. each individual must have a unique identifier, so to be safe I started with an ID of 280*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mv ustacks_counts_lane5.sh ../ustacks_counts_lane5.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I can run this, I need to unzip all of my gzipped fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ran at command line\n",
    "\n",
    "#command one\n",
    "sample_array=`cat ../scripts/L5_sampleList.txt`\n",
    "\n",
    "#command two\n",
    "for file in $sample_array\n",
    "do\n",
    "\techo $file\n",
    "\tgzip -d $file.fq.gz\n",
    "\techo 'file unzipped'\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ran in the command line the shell script from above\n",
    "./ustacks_counts_lane5.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The counts didn't work, so I used the python script below instead to find the number of loci and number of raw fastq reads for each sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts\n"
     ]
    }
   ],
   "source": [
    "cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### This script counts the read depth of each process_radtags fastq output file ###\r\n",
      "\r\n",
      "\r\n",
      "import argparse \r\n",
      "\r\n",
      "parser = argparse.ArgumentParser(description=\"count number of consensus seqs in .tags files\")\r\n",
      "\r\n",
      "parser.add_argument(\"-s\", \"--samples\", help=\"file with list of samples (if paired end, should include .1 at end)\")\r\n",
      "parser.add_argument(\"-d\", \"--directory\", help=\"local path with directory with fastq files\")\r\n",
      "parser.add_argument(\"-os\", \"--outputshell\", help=\"bash shell script file name. must have file extension .sh\")\r\n",
      "parser.add_argument(\"-of\", \"--output\", help=\"text file name to store read depths, with local path. Do not include file extension\")\r\n",
      "\r\n",
      "args = parser.parse_args()\r\n",
      "import subprocess\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 countreads_fastq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run in terminal\n",
    "python countreads_fastq.py \\\n",
    "-s L5_sampleList.txt \\\n",
    "-d ../samplesT142 \\\n",
    "-os countreads_fastq_lane5.sh \\\n",
    "-of lane5_fastq_readcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### This script counts the number of loci in each ustacks tags file ###\r\n",
      "\r\n",
      "\r\n",
      "import argparse \r\n",
      "\r\n",
      "parser = argparse.ArgumentParser(description=\"count number of consensus seqs in .tags files\")\r\n",
      "\r\n",
      "parser.add_argument(\"-s\", \"--samples\", help=\"file with list of samples\")\r\n",
      "parser.add_argument(\"-d\", \"--directory\", help=\"stacks directory with tags files; can be local path, don't include final '/'\")\r\n",
      "parser.add_argument(\"-o\", \"--output\", help=\"output file name with local path\")\r\n",
      "\r\n",
      "args = parser.parse_args()\r\n",
      "\r\n",
      "samplefile= open(args.samples, \"r\")\r\n",
      "outfile = open(args.output, \"w\")\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 countloci_tagsfiles.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run in terminal\n",
    "python countloci_tagsfiles.py \\\n",
    "-s L5_sampleList.txt \\\n",
    "-d ../stacks_b7 \\\n",
    "-o locicounts_lane5.txt \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "#### 8/16/2017\n",
    "\n",
    "I created an excel spreadsheet which compares the # of reads / # tags per individual, and the graphical comparisons of that data which can be found in [this Jupyter notebook](https://github.com/mfisher5/PCod-Korea-repo/blob/master/notebooks/Stacks%20batch%207%20-%20pipeline%20analyses.ipynb). \n",
    "\n",
    "<br>\n",
    "#### 8/17/2017\n",
    "I've decided to re-run `cstacks` with a few of my new samples in the catalog. \n",
    "\n",
    "<br>\n",
    "### cstacks --> populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/PCod-Korea-repo/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Generate Shell Script to Run cstacks --> populations ######\r\n",
      "\r\n",
      "## MF 3/8/2017 modified 4/29/2017\r\n",
      "## For US Cod Data modified for Korean Cod Data\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "## At Command Line: python cstacks_populations_genShell_3-8 ARG1 ARG2\r\n",
      "##---- ARG1 = samples for cstacks file \r\n",
      "##---- ARG2 = complete sample list file; in this script should be the population map\r\n"
     ]
    }
   ],
   "source": [
    "!head cstacks_populations_genShell_8-17.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python cstacks_populations_genShell_8-17.py \\\n",
    "samples_for_cstacks_b7.txt \\\n",
    "PopMap_L1-5.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#cstacks\r\n",
      "cstacks -b 7 -s ../stacks_b7/PO010715_28.1 -s ../stacks_b7/PO031715_03 -s ../stacks_b7/PO031715_23 -s ../stacks_b7/PO031715_04 -s ../stacks_b7/PO020515_15.1 -s ../stacks_b7/PO010715_02 -s ../stacks_b7/PO010715_12 -s ../stacks_b7/PO020515_14.1 -s ../stacks_b7/PO031715_19.1 -s ../stacks_b7/PO020515_10.1 -s ../stacks_b7/GE011215_10.1 -s ../stacks_b7/GEO012315_12 -s ../stacks_b7/GE011215_18 -s ../stacks_b7/GE011215_22 -s ../stacks_b7/GEO012315_18 -s ../stacks_b7/GEO012315_02 -s ../stacks_b7/GE011215_20.1 -s ../stacks_b7/GE011215_14.1 -s ../stacks_b7/GE011215_28 -s ../stacks_b7/GEO012315_21 -s ../stacks_b7/NA021015_25 -s ../stacks_b7/NA021015_30 -s ../stacks_b7/NA021015_21.1 -s ../stacks_b7/NA021015_26 -s ../stacks_b7/NA021015_13.1 -s ../stacks_b7/NA021015_23 -s ../stacks_b7/NA021015_16.1 -s ../stacks_b7/NA021015_22.1 -s ../stacks_b7/NA021015_17.1 -s ../stacks_b7/NA021015_14.1 -s ../stacks_b7/YS_121316_13 -s ../stacks_b7/YS121315_16 -s ../stacks_b7/YS_121316_07 -s ../stacks_b7/YS_121316_26 -s ../stacks_b7/YS_121316_01 -s ../stacks_b7/YS121315_15 -s ../stacks_b7/YS_121316_17 -s ../stacks_b7/YS_121316_21 -s ../stacks_b7/YS_121316_22 -s ../stacks_b7/YS_121316_24 -s ../stacks_b7/JUK07_30 -s ../stacks_b7/JUK07_32 -s ../stacks_b7/JUK07_08 -s ../stacks_b7/JUK07_02.1 -s ../stacks_b7/JUK07_15 -s ../stacks_b7/JUK07_29.1 -s ../stacks_b7/JUK07_19 -s ../stacks_b7/JUK07_27 -s ../stacks_b7/JUK07_09.1 -s ../stacks_b7/JUK07_26 -s ../stacks_b7/JB121807_44 -s ../stacks_b7/JB121807_31.1 -s ../stacks_b7/JB121807_46 -s ../stacks_b7/JB121807_38.1 -s ../stacks_b7/JB121807_14.1 -s ../stacks_b7/JB121807_33.1 -s ../stacks_b7/JB121807_03.1 -s ../stacks_b7/JB121807_11.1 -s ../stacks_b7/JB121807_21.1 -s ../stacks_b7/JB121807_37 -s ../stacks_b7/JB021108_19.1 -s ../stacks_b7/JB021108_05 -s ../stacks_b7/JB021108_32 -s ../stacks_b7/JB021108_45 -s ../stacks_b7/JB021108_12.1 -s ../stacks_b7/JB021108_37.1 -s ../stacks_b7/JB021108_30 -s ../stacks_b7/JB021108_16 -s ../stacks_b7/JB021108_46.1 -s ../stacks_b7/JB021108_48.1 -s ../stacks_b7/GEO020414_24_300 -s ../stacks_b7/GEO020414_7 -s ../stacks_b7/GEO020414_4 -s ../stacks_b7/GEO020414_11_300 -s ../stacks_b7/GEO020414_9_300 -s ../stacks_b7/GEO020414_3 -s ../stacks_b7/GEO020414_23_300 -s ../stacks_b7/GEO020414_13_300 -s ../stacks_b7/GEO020414_16_300 -s ../stacks_b7/GEO020414_8_300 -s ../stacks_b7/BOR07_14 -s ../stacks_b7/BOR07_11.1 -s ../stacks_b7/BOR07_22 -s ../stacks_b7/BOR07_12.1 -s ../stacks_b7/BOR07_07.1 -s ../stacks_b7/BOR07_09 -s ../stacks_b7/BOR07_02.1 -s ../stacks_b7/BOR07_04 -s ../stacks_b7/BOR07_08.1 -s ../stacks_b7/BOR07_17.1 -o ../stacks_b7 -n 3 -p 6\r\n"
     ]
    }
   ],
   "source": [
    "!head cstacks_populations_8-17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}